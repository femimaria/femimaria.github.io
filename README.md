This project demonstrates an end-to-end A/B testing setup using two landing page variations hosted on GitHub Pages. The goal was to identify which version drives better user engagement and conversions.
Project Overview

The project involves designing, deploying, and analyzing two different landing page versions (Version A and Version B) to evaluate which performs better in terms of user interaction and signup rate.

Objectives
Test design and content variations to improve conversion rates.
Measure user engagement using analytics tools.
Derive actionable insights from real user behavior.

Tech Stack & Tools
Frontend: HTML
Hosting: GitHub Pages
Analytics: Microsoft Clarity
Form Handling: Formspree

Experiment Setup

Version A & B Creation:

Two unique landing pages were designed with variations in layout, CTA placement, and color scheme.

Traffic Distribution:

Visitors were randomly directed to one of the two pages using a simple redirect script.

User Interaction Tracking:

Microsoft Clarity: Recorded heatmaps and session replays.
Formspree: Collected form submissions for signup conversion data.

Performance Metrics:

Click-through rate (CTR)
Scroll depth percentage
Signup conversion rate

Analysis
After data collection, results were analyzed to determine:
Which variation generated higher engagement and conversions.
Behavioral differences observed in user heatmaps and session recordings.
Recommendations for improving future landing page design.

Key Learnings
How to implement and measure A/B tests without paid tools.
The impact of small design changes on user behavior.
Integration of multiple analytics platforms for deeper insights.

Live Demo
Version A: 
Version B: Link to Page B

ðŸ“¬ Contact
Femi Maria Sebastian
fmariasebastian@gmail.com
